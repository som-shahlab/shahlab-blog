@ARTICLE{Day2024-wh,
  title     = "Interaction between clinicians and artificial intelligence to
               detect fetal atrioventricular septal defects on ultrasound: how
               can we optimize collaborative performance?",
  author    = "Day, T G and Matthew, J and Budd, S F and Venturini, L and
               Wright, R and Farruggia, A and Vigneswaran, T V and Zidere, V
               and Hajnal, J V and Razavi, R and Simpson, J M and Kainz, B",
  abstract  = "OBJECTIVES: Artificial intelligence (AI) has shown promise in
               improving the performance of fetal ultrasound screening in
               detecting congenital heart disease (CHD). The effect of giving
               AI advice to human operators has not been studied in this
               context. Giving additional information about AI model workings,
               such as confidence scores for AI predictions, may be a way of
               further improving performance. Our aims were to investigate
               whether AI advice improved overall diagnostic accuracy (using a
               single CHD lesion as an exemplar), and to determine what, if
               any, additional information given to clinicians optimized the
               overall performance of the clinician-AI team. METHODS: An AI
               model was trained to classify a single fetal CHD lesion
               (atrioventricular septal defect (AVSD)), using a retrospective
               cohort of 121 130 cardiac four-chamber images extracted from 173
               ultrasound scan videos (98 with normal hearts, 75 with AVSD); a
               ResNet50 model architecture was used. Temperature scaling of
               model prediction probability was performed on a validation set,
               and gradient-weighted class activation maps (grad-CAMs)
               produced. Ten clinicians (two consultant fetal cardiologists,
               three trainees in pediatric cardiology and five fetal cardiac
               sonographers) were recruited from a center of fetal cardiology
               to participate. Each participant was shown 2000 fetal
               four-chamber images in a random order (1000 normal and 1000
               AVSD). The dataset comprised 500 images, each shown in four
               conditions: (1) image alone without AI output; (2) image with
               binary AI classification; (3) image with AI model confidence;
               and (4) image with grad-CAM image overlays. The clinicians were
               asked to classify each image as normal or AVSD. RESULTS: A total
               of 20 000 image classifications were recorded from 10
               clinicians. The AI model alone achieved an accuracy of 0.798
               (95\% CI, 0.760-0.832), a sensitivity of 0.868 (95\% CI,
               0.834-0.902) and a specificity of 0.728 (95\% CI, 0.702-0.754),
               and the clinicians without AI achieved an accuracy of 0.844
               (95\% CI, 0.834-0.854), a sensitivity of 0.827 (95\% CI,
               0.795-0.858) and a specificity of 0.861 (95\% CI, 0.828-0.895).
               Showing a binary (normal or AVSD) AI model output resulted in
               significant improvement in accuracy to 0.865 (P < 0.001). This
               effect was seen in both experienced and less-experienced
               participants. Giving incorrect AI advice resulted in a
               significant deterioration in overall accuracy, from 0.761 to
               0.693 (P < 0.001), which was driven by an increase in both
               Type-I and Type-II errors by the clinicians. This effect was
               worsened by showing model confidence (accuracy, 0.649; P <
               0.001) or grad-CAM (accuracy, 0.644; P < 0.001). CONCLUSIONS: AI
               has the potential to improve performance when used in
               collaboration with clinicians, even if the model performance
               does not reach expert level. Giving additional information about
               model workings such as model confidence and class activation map
               image overlays did not improve overall performance, and actually
               worsened performance for images for which the AI model was
               incorrect. \copyright{} 2024 The Authors. Ultrasound in
               Obstetrics \& Gynecology published by John Wiley \& Sons Ltd on
               behalf of International Society of Ultrasound in Obstetrics and
               Gynecology.",
  journal   = "Ultrasound Obstet. Gynecol.",
  publisher = "Wiley",
  volume    =  64,
  number    =  1,
  pages     = "28--35",
  month     =  jul,
  year      =  2024,
  keywords  = "AI; artificial intelligence; atrioventricular septal defect;
               congenital heart disease; fetal cardiology; fetal medicine;
               machine learning",
  copyright = "http://creativecommons.org/licenses/by/4.0/",
  language  = "en"
}

@ARTICLE{Jabbour2023-rd,
  title    = "Measuring the impact of {AI} in the diagnosis of hospitalized
              patients: A randomized clinical vignette survey study",
  author   = "Jabbour, Sarah and Fouhey, David and Shepard, Stephanie and
              Valley, Thomas S and Kazerooni, Ella A and Banovic, Nikola and
              Wiens, Jenna and Sjoding, Michael W",
  abstract = "Importance: Artificial intelligence (AI) could support clinicians
              when diagnosing hospitalized patients; however, systematic bias
              in AI models could worsen clinician diagnostic accuracy. Recent
              regulatory guidance has called for AI models to include
              explanations to mitigate errors made by models, but the
              effectiveness of this strategy has not been established.
              Objectives: To evaluate the impact of systematically biased AI on
              clinician diagnostic accuracy and to determine if image-based AI
              model explanations can mitigate model errors. Design, Setting,
              and Participants: Randomized clinical vignette survey study
              administered between April 2022 and January 2023 across 13 US
              states involving hospitalist physicians, nurse practitioners, and
              physician assistants. Interventions: Clinicians were shown 9
              clinical vignettes of patients hospitalized with acute
              respiratory failure, including their presenting symptoms,
              physical examination, laboratory results, and chest radiographs.
              Clinicians were then asked to determine the likelihood of
              pneumonia, heart failure, or chronic obstructive pulmonary
              disease as the underlying cause(s) of each patient's acute
              respiratory failure. To establish baseline diagnostic accuracy,
              clinicians were shown 2 vignettes without AI model input.
              Clinicians were then randomized to see 6 vignettes with AI model
              input with or without AI model explanations. Among these 6
              vignettes, 3 vignettes included standard-model predictions, and 3
              vignettes included systematically biased model predictions. Main
              Outcomes and Measures: Clinician diagnostic accuracy for
              pneumonia, heart failure, and chronic obstructive pulmonary
              disease. Results: Median participant age was 34 years (IQR,
              31-39) and 241 (57.7\%) were female. Four hundred fifty-seven
              clinicians were randomized and completed at least 1 vignette,
              with 231 randomized to AI model predictions without explanations,
              and 226 randomized to AI model predictions with explanations.
              Clinicians' baseline diagnostic accuracy was 73.0\% (95\% CI,
              68.3\% to 77.8\%) for the 3 diagnoses. When shown a standard AI
              model without explanations, clinician accuracy increased over
              baseline by 2.9 percentage points (95\% CI, 0.5 to 5.2) and by
              4.4 percentage points (95\% CI, 2.0 to 6.9) when clinicians were
              also shown AI model explanations. Systematically biased AI model
              predictions decreased clinician accuracy by 11.3 percentage
              points (95\% CI, 7.2 to 15.5) compared with baseline and
              providing biased AI model predictions with explanations decreased
              clinician accuracy by 9.1 percentage points (95\% CI, 4.9 to
              13.2) compared with baseline, representing a nonsignificant
              improvement of 2.3 percentage points (95\% CI, -2.7 to 7.2)
              compared with the systematically biased AI model. Conclusions and
              Relevance: Although standard AI models improve diagnostic
              accuracy, systematically biased AI models reduced diagnostic
              accuracy, and commonly used image-based AI model explanations did
              not mitigate this harmful effect. Trial Registration:
              ClinicalTrials.gov Identifier: NCT06098950.",
  journal  = "JAMA",
  volume   =  330,
  number   =  23,
  pages    = "2275--2284",
  month    =  dec,
  year     =  2023,
  language = "en"
}

@ARTICLE{Lin2024-oo,
  title     = "{AI-enabled} electrocardiography alert intervention and
               all-cause mortality: a pragmatic randomized clinical trial",
  author    = "Lin, Chin-Sheng and Liu, Wei-Ting and Tsai, Dung-Jang and Lou,
               Yu-Sheng and Chang, Chiao-Hsiang and Lee, Chiao-Chin and Fang,
               Wen-Hui and Wang, Chih-Chia and Chen, Yen-Yuan and Lin,
               Wei-Shiang and Cheng, Cheng-Chung and Lee, Chia-Cheng and Wang,
               Chih-Hung and Tsai, Chien-Sung and Lin, Shih-Hua and Lin, Chin",
  abstract  = "The early identification of vulnerable patients has the
               potential to improve outcomes but poses a substantial challenge
               in clinical practice. This study evaluated the ability of an
               artificial intelligence (AI)-enabled electrocardiogram (ECG) to
               identify hospitalized patients with a high risk of mortality in
               a multisite randomized controlled trial involving 39 physicians
               and 15,965 patients. The AI-ECG alert intervention included an
               AI report and warning messages delivered to the physicians,
               flagging patients predicted to be at high risk of mortality. The
               trial met its primary outcome, finding that implementation of
               the AI-ECG alert was associated with a significant reduction in
               all-cause mortality within 90 days: 3.6\% patients in the
               intervention group died within 90 days, compared to 4.3\% in the
               control group (4.3\%) (hazard ratio (HR) = 0.83, 95\% confidence
               interval (CI) = 0.70-0.99). A prespecified analysis showed that
               reduction in all-cause mortality associated with the AI-ECG
               alert was observed primarily in patients with high-risk ECGs (HR
               = 0.69, 95\% CI = 0.53-0.90). In analyses of secondary outcomes,
               patients in the intervention group with high-risk ECGs received
               increased levels of intensive care compared to the control
               group; for the high-risk ECG group of patients, implementation
               of the AI-ECG alert was associated with a significant reduction
               in the risk of cardiac death (0.2\% in the intervention arm
               versus 2.4\% in the control arm, HR = 0.07, 95\% CI =
               0.01-0.56). While the precise means by which implementation of
               the AI-ECG alert led to decreased mortality are to be fully
               elucidated, these results indicate that such implementation
               assists in the detection of high-risk patients, prompting timely
               clinical care and reducing mortality. ClinicalTrials.gov
               registration: NCT05118035 .",
  journal   = "Nat. Med.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  30,
  number    =  5,
  pages     = "1461--1470",
  month     =  may,
  year      =  2024,
  copyright = "https://www.springernature.com/gp/researchers/text-and-data-mining",
  language  = "en"
}

@ARTICLE{Han2024-tq,
  title     = "Artificial intelligence-assisted diagnosis of congenital heart
               disease and associated pulmonary arterial hypertension from
               chest radiographs: A multi-reader multi-case study",
  author    = "Han, Pei-Lun and Jiang, Lei and Cheng, Jun-Long and Shi, Ke and
               Huang, Shan and Jiang, Yu and Jiang, Li and Xia, Qing and Li,
               Yi-Yue and Zhu, Min and Li, Kang and Yang, Zhi-Gang",
  abstract  = "OBJECTIVES: To explore the possibility of automatic diagnosis of
               congenital heart disease (CHD) and pulmonary arterial
               hypertension associated with CHD (PAH-CHD) from chest
               radiographs using artificial intelligence (AI) technology and to
               evaluate whether AI assistance could improve clinical diagnostic
               accuracy. MATERIALS AND METHODS: A total of 3255 frontal
               preoperative chest radiographs (1174 CHD of any type and 2081
               non-CHD) were retrospectively obtained. In this study, we
               adopted ResNet18 pretrained with the ImageNet database to
               establish diagnostic models. Radiologists diagnosed CHD/PAH-CHD
               from 330/165 chest radiographs twice: the first time, 50\% of
               the images were accompanied by AI-based classification; after a
               month, the remaining 50\% were accompanied by AI-based
               classification. Diagnostic results were compared between the
               radiologists and AI models, and between radiologists with and
               without AI assistance. RESULTS: The AI model achieved an average
               area under the receiver operating characteristic curve (AUC) of
               0.948 (sensitivity: 0.970, specificity: 0.982) for CHD diagnoses
               and an AUC of 0.778 (sensitivity: 0.632, specificity: 0.925) for
               identifying PAH-CHD. In the 330 balanced (165 CHD and 165
               non-CHD) testing set, AI achieved higher AUCs than all 5
               radiologists in the identification of CHD (0.670-0.858) and
               PAH-CHD (0.610-0.688). With AI assistance, the mean $\pm$
               standard error AUC of radiologists was significantly improved
               for CHD ($\Delta$AUC + 0.096, 95 \% CI: 0.001-0.190; P = 0.048)
               and PAH-CHD ($\Delta$AUC + 0.066, 95 \% CI: 0.010-0.122; P =
               0.031) diagnosis. CONCLUSION: Chest radiograph-based AI models
               can detect CHD and PAH-CHD automatically. AI assistance improved
               radiologists' diagnostic accuracy, which may facilitate a timely
               initial diagnosis of CHD and PAH-CHD.",
  journal   = "Eur. J. Radiol.",
  publisher = "Elsevier BV",
  volume    =  171,
  number    =  111277,
  pages     = "111277",
  month     =  feb,
  year      =  2024,
  keywords  = "Artificial intelligence; Congenital heart disease; Multi-reader
               multi-case study; Pulmonary arterial hypertension; Radiography;
               Radiologists",
  language  = "en"
}

@ARTICLE{Nayak2023-em,
  title    = "Use of voice-based conversational artificial intelligence for
              basal insulin prescription management among patients with type 2
              diabetes: A randomized clinical trial",
  author   = "Nayak, Ashwin and Vakili, Sharif and Nayak, Kristen and Nikolov,
              Margaret and Chiu, Michelle and Sosseinheimer, Philip and
              Talamantes, Sarah and Testa, Stefano and Palanisamy, Srikanth and
              Giri, Vinay and Schulman, Kevin",
  abstract = "Importance: Optimizing insulin therapy for patients with type 2
              diabetes can be challenging given the need for frequent dose
              adjustments. Most patients receive suboptimal doses and do not
              achieve glycemic control. Objective: To examine whether a
              voice-based conversational artificial intelligence (AI)
              application can help patients with type 2 diabetes titrate basal
              insulin at home to achieve rapid glycemic control. Design,
              Setting, and Participants: In this randomized clinical trial
              conducted at 4 primary care clinics at an academic medical center
              from March 1, 2021, to December 31, 2022, 32 adults with type 2
              diabetes requiring initiation or adjustment of once-daily basal
              insulin were followed up for 8 weeks. Statistical analysis was
              performed from January to February 2023. Interventions:
              Participants were randomized in a 1:1 ratio to receive basal
              insulin management with a voice-based conversational AI
              application or standard of care. Main Outcomes and Measures:
              Primary outcomes were time to optimal insulin dose (number of
              days needed to achieve glycemic control), insulin adherence, and
              change in composite survey scores measuring diabetes-related
              emotional distress and attitudes toward health technology and
              medication adherence. Secondary outcomes were glycemic control
              and glycemic improvement. Analysis was performed on an
              intent-to-treat basis. Results: The study population included 32
              patients (mean [SD] age, 55.1 [12.7] years; 19 women [59.4\%]).
              Participants in the voice-based conversational AI group more
              quickly achieved optimal insulin dosing compared with the
              standard of care group (median, 15 days [IQR, 6-27 days] vs >56
              days [IQR, >29.5 to >56 days]; a significant difference in
              time-to-event curves; P = .006) and had better insulin adherence
              (mean [SD], 82.9\% [20.6\%] vs 50.2\% [43.0\%]; difference,
              32.7\% [95\% CI, 8.0\%-57.4\%]; P = .01). Participants in the
              voice-based conversational AI group were also more likely than
              those in the standard of care group to achieve glycemic control
              (13 of 16 [81.3\%; 95\% CI, 53.7\%-95.0\%] vs 4 of 16 [25.0\%;
              95\% CI, 8.3\%-52.6\%]; difference, 56.3\% [95\% CI,
              21.4\%-91.1\%]; P = .005) and glycemic improvement, as measured
              by change in mean (SD) fasting blood glucose level (-45.9 [45.9]
              mg/dL [95\% CI, -70.4 to -21.5 mg/dL] vs 23.0 [54.7] mg/dL [95\%
              CI, -8.6 to 54.6 mg/dL]; difference, -68.9 mg/dL [95\% CI, -107.1
              to -30.7 mg/dL]; P = .001). There was a significant difference
              between the voice-based conversational AI group and the standard
              of care group in change in composite survey scores measuring
              diabetes-related emotional distress (-1.9 points vs 1.7 points;
              difference, -3.6 points [95\% CI, -6.8 to -0.4 points]; P = .03).
              Conclusions and Relevance: In this randomized clinical trial of a
              voice-based conversational AI application that provided
              autonomous basal insulin management for adults with type 2
              diabetes, participants in the AI group had significantly improved
              time to optimal insulin dose, insulin adherence, glycemic
              control, and diabetes-related emotional distress compared with
              those in the standard of care group. These findings suggest that
              voice-based digital health solutions can be useful for medication
              titration. Trial Registration: ClinicalTrials.gov Identifier:
              NCT05081011.",
  journal  = "JAMA Netw. Open",
  volume   =  6,
  number   =  12,
  pages    = "e2340232",
  month    =  dec,
  year     =  2023,
  language = "en"
}

@ARTICLE{Hwang2023-lv,
  title    = "Conventional versus artificial intelligence-assisted
              interpretation of chest radiographs in patients with acute
              respiratory symptoms in emergency department: A pragmatic
              randomized clinical trial",
  author   = "Hwang, Eui Jin and Goo, Jin Mo and Nam, Ju Gang and Park, Chang
              Min and Hong, Ki Jeong and Kim, Ki Hong",
  abstract = "OBJECTIVE: It is unknown whether artificial intelligence-based
              computer-aided detection (AI-CAD) can enhance the accuracy of
              chest radiograph (CR) interpretation in real-world clinical
              practice. We aimed to compare the accuracy of CR interpretation
              assisted by AI-CAD to that of conventional interpretation in
              patients who presented to the emergency department (ED) with
              acute respiratory symptoms using a pragmatic randomized
              controlled trial. MATERIALS AND METHODS: Patients who underwent
              CRs for acute respiratory symptoms at the ED of a tertiary
              referral institution were randomly assigned to intervention group
              (with assistance from an AI-CAD for CR interpretation) or control
              group (without AI assistance). Using a commercial AI-CAD system
              (Lunit INSIGHT CXR, version 2.0.2.0; Lunit Inc.). Other clinical
              practices were consistent with standard procedures. Sensitivity
              and false-positive rates of CR interpretation by duty trainee
              radiologists for identifying acute thoracic diseases were the
              primary and secondary outcomes, respectively. The reference
              standards for acute thoracic disease were established based on a
              review of the patient's medical record at least 30 days after the
              ED visit. RESULTS: We randomly assigned 3576 participants to
              either the intervention group (1761 participants; mean age $\pm$
              standard deviation, 65 $\pm$ 17 years; 978 males; acute thoracic
              disease in 472 participants) or the control group (1815
              participants; 64 $\pm$ 17 years; 988 males; acute thoracic
              disease in 491 participants). The sensitivity (67.2\% [317/472]
              in the intervention group vs. 66.0\% [324/491] in the control
              group; odds ratio, 1.02 [95\% confidence interval, 0.70-1.49]; P
              = 0.917) and false-positive rate (19.3\% [249/1289] vs. 18.5\%
              [245/1324]; odds ratio, 1.00 [95\% confidence interval,
              0.79-1.26]; P = 0.985) of CR interpretation by duty radiologists
              were not associated with the use of AI-CAD. CONCLUSION: AI-CAD
              did not improve the sensitivity and false-positive rate of CR
              interpretation for diagnosing acute thoracic disease in patients
              with acute respiratory symptoms who presented to the ED.",
  journal  = "Korean J. Radiol.",
  volume   =  24,
  number   =  3,
  pages    = "259--270",
  month    =  mar,
  year     =  2023,
  keywords = "Artificial intelligence; Chest radiography; Clinical trial;
              Computer-aided detection; Deep learning; Diagnostic accuracy;
              Emergency radiology",
  language = "en"
}

@ARTICLE{Goh2023-vb,
  title    = "{ChatGPT} influence on medical decision-making, bias, and equity:
              A randomized study of clinicians evaluating clinical vignettes",
  author   = "Goh, Ethan and Bunning, Bryan and Khoong, Elaine and Gallo,
              Robert and Milstein, Arnold and Centola, Damon and Chen, Jonathan
              H",
  abstract = "In a randomized, pre-post intervention study, we evaluated the
              influence of a large language model (LLM) generative AI system on
              accuracy of physician decision-making and bias in healthcare. 50
              US-licensed physicians reviewed a video clinical vignette,
              featuring actors representing different demographics (a White
              male or a Black female) with chest pain. Participants were asked
              to answer clinical questions around triage, risk, and treatment
              based on these vignettes, then asked to reconsider after
              receiving advice generated by ChatGPT+ (GPT4). The primary
              outcome was the accuracy of clinical decisions based on
              pre-established evidence-based guidelines. Results showed that
              physicians are willing to change their initial clinical
              impressions given AI assistance, and that this led to a
              significant improvement in clinical decision-making accuracy in a
              chest pain evaluation scenario without introducing or
              exacerbating existing race or gender biases. A survey of
              physician participants indicates that the majority expect LLM
              tools to play a significant role in clinical decision making.",
  journal  = "medRxiv",
  month    =  nov,
  year     =  2023,
  language = "en"
}

@ARTICLE{Wang2023-hb,
  title    = "Artificial intelligence suppression as a strategy to mitigate
              artificial intelligence automation bias",
  author   = "Wang, Ding-Yu and Ding, Jia and Sun, An-Lan and Liu, Shang-Gui
              and Jiang, Dong and Li, Nan and Yu, Jia-Kuo",
  abstract = "BACKGROUND: Incorporating artificial intelligence (AI) into
              clinics brings the risk of automation bias, which potentially
              misleads the clinician's decision-making. The purpose of this
              study was to propose a potential strategy to mitigate automation
              bias. METHODS: This was a laboratory study with a randomized
              cross-over design. The diagnosis of anterior cruciate ligament
              (ACL) rupture, a common injury, on magnetic resonance imaging
              (MRI) was used as an example. Forty clinicians were invited to
              diagnose 200 ACLs with and without AI assistance. The AI's
              correcting and misleading (automation bias) effects on the
              clinicians' decision-making processes were analyzed. An ordinal
              logistic regression model was employed to predict the correcting
              and misleading probabilities of the AI. We further proposed an AI
              suppression strategy that retracted AI diagnoses with a higher
              misleading probability and provided AI diagnoses with a higher
              correcting probability. RESULTS: The AI significantly increased
              clinicians' accuracy from 87.2\%$\pm$13.1\% to 96.4\%$\pm$1.9\%
              (P < .001). However, the clinicians' errors in the AI-assisted
              round were associated with automation bias, accounting for 45.5\%
              of the total mistakes. The automation bias was found to affect
              clinicians of all levels of expertise. Using a logistic
              regression model, we identified an AI output zone with higher
              probability to generate misleading diagnoses. The proposed AI
              suppression strategy was estimated to decrease clinicians'
              automation bias by 41.7\%. CONCLUSION: Although AI improved
              clinicians' diagnostic performance, automation bias was a serious
              problem that should be addressed in clinical practice. The
              proposed AI suppression strategy is a practical method for
              decreasing automation bias.",
  journal  = "J. Am. Med. Inform. Assoc.",
  volume   =  30,
  number   =  10,
  pages    = "1684--1692",
  month    =  sep,
  year     =  2023,
  keywords = "AI suppression; automation bias; clinician-AI interaction; deep
              learning",
  language = "en"
}

@ARTICLE{Goddard2012-wf,
  title     = "Automation bias: a systematic review of frequency, effect
               mediators, and mitigators",
  author    = "Goddard, Kate and Roudsari, Abdul and Wyatt, Jeremy C",
  abstract  = "Automation bias (AB)--the tendency to over-rely on
               automation--has been studied in various academic fields.
               Clinical decision support systems (CDSS) aim to benefit the
               clinical decision-making process. Although most research shows
               overall improved performance with use, there is often a failure
               to recognize the new errors that CDSS can introduce. With a
               focus on healthcare, a systematic review of the literature from
               a variety of research fields has been carried out, assessing the
               frequency and severity of AB, the effect mediators, and
               interventions potentially mitigating this effect. This is
               discussed alongside automation-induced complacency, or
               insufficient monitoring of automation output. A mix of subject
               specific and freetext terms around the themes of automation,
               human-automation interaction, and task performance and error
               were used to search article databases. Of 13 821 retrieved
               papers, 74 met the inclusion criteria. User factors such as
               cognitive style, decision support systems (DSS), and task
               specific experience mediated AB, as did attitudinal driving
               factors such as trust and confidence. Environmental mediators
               included workload, task complexity, and time constraint, which
               pressurized cognitive resources. Mitigators of AB included
               implementation factors such as training and emphasizing user
               accountability, and DSS design factors such as the position of
               advice on the screen, updated confidence levels attached to DSS
               output, and the provision of information versus recommendation.
               By uncovering the mechanisms by which AB operates, this review
               aims to help optimize the clinical decision-making process for
               CDSS developers and healthcare practitioners.",
  journal   = "J. Am. Med. Inform. Assoc.",
  publisher = "Oxford University Press (OUP)",
  volume    =  19,
  number    =  1,
  pages     = "121--127",
  month     =  jan,
  year      =  2012,
  language  = "en"
}

